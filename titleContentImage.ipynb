{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import jsonlines\n",
    "import os\n",
    "\n",
    "os.environ['KERAS_BACKEND'] = 'theano'\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers.merge import concatenate\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Dense, Input\n",
    "from keras.layers import Embedding, Merge, Dropout, LSTM, Bidirectional\n",
    "from keras.models import Model\n",
    "import AttentionwithContext as ac\n",
    "\n",
    "import tensorflow as tf\n",
    "from config import Config\n",
    "from cnn_model import cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "MAX_NB_WORDS = 20000\n",
    "EMBEDDING_DIM = 100\n",
    "VALIDATION_SPLIT = 0.1111806\n",
    "\n",
    "count = 0\n",
    "full_count = 0\n",
    "train_val_data = []\n",
    "test_data = []\n",
    "\n",
    "with jsonlines.open('instances.jsonl') as reader:\n",
    "    for obj in reader.iter(type=dict, skip_invalid=True):\n",
    "        count += 1\n",
    "        full_count+=1\n",
    "        if (count > 17600):\n",
    "            test_data.append(obj)\n",
    "        if(count<=17600):\n",
    "            train_val_data.append(obj)\n",
    "\n",
    "count = 0\n",
    "truth_data = []\n",
    "with jsonlines.open('truth.jsonl') as reader:\n",
    "    for obj in reader.iter(type=dict, skip_invalid=True):\n",
    "        truth_data.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for all datasets except for SST.\n",
    "    Original taken from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "    string = re.sub(r\",\", \" \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    string = re.sub(r\"@\", \"\", string)\n",
    "    return string.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgModel(vals_df):\n",
    "    # model = VGG16(weights='imagenet', include_top=False)\n",
    "    # model.summary()\n",
    "    img_features = []\n",
    "    config = Config()\n",
    "    images = tf.placeholder(\n",
    "        dtype=tf.float32,\n",
    "        shape=[config.batch_size] + config.image_shape)\n",
    "\n",
    "    sess = tf.Session()\n",
    "\n",
    "    model = cnn_model(config)\n",
    "    features = model.build_vgg16(images)\n",
    "    model.load_cnn(sess,config.vgg16_file)\n",
    "\n",
    "    for entry in vals_df.values:\n",
    "        img_path = entry[1][0]\n",
    "        # print(img_path)\n",
    "        img = image.load_img(img_path, target_size=(224, 224,3))\n",
    "        img_data = image.img_to_array(img)\n",
    "        img_data = np.expand_dims(img_data, axis=0)\n",
    "        img_data = preprocess_input(img_data)\n",
    "\n",
    "        # vgg16_feature = model.predict(img_data)\n",
    "\n",
    "        vgg16_feature = sess.run(features,feed_dict={images:img_data})\n",
    "        img_features.append(vgg16_feature[0])\n",
    "    tf.reset_default_graph()\n",
    "    return img_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_padded_sequences(df):\n",
    "    tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "    tokenizer.fit_on_texts(df)\n",
    "    sequences = tokenizer.texts_to_sequences(df)\n",
    "    word_index = tokenizer.word_index\n",
    "    print('Found %s unique tokens.' % len(word_index))\n",
    "    data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    return data, word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content_df(vals):\n",
    "    content_df = []\n",
    "    for i in range(len(vals)): ## For content\n",
    "        text = []\n",
    "        for j in range(2, 7):\n",
    "            if(j==5):\n",
    "                continue\n",
    "            else:\n",
    "                k = vals[i][j]\n",
    "                if(j==6):\n",
    "                    text.append(k)\n",
    "                else:\n",
    "                    text += (k)\n",
    "        words = \"\"\n",
    "        for string in text:\n",
    "            string = clean_str(string)\n",
    "            words += \" \".join(string.split())\n",
    "        content_df += [words]\n",
    "    return content_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title_df(vals):\n",
    "    titles_df = []\n",
    "    for i in range(len(vals)): ## For titles\n",
    "        text = []\n",
    "        k = vals[i][5]\n",
    "        text+=(k)\n",
    "        words = \"\"\n",
    "        for string in text:\n",
    "            string = clean_str(string)\n",
    "            words +=\" \".join(string.split())\n",
    "        titles_df+=[words]\n",
    "    return titles_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(vals_df):\n",
    "    labels = []\n",
    "    for i in vals_df.values:\n",
    "        if(i[8]==\"clickbait\"):\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final vals length 9295\n"
     ]
    }
   ],
   "source": [
    "final_vals = []\n",
    "data_df = pd.DataFrame.from_dict(train_val_data)\n",
    "truth_data_df = pd.DataFrame.from_dict(truth_data)\n",
    "train = pd.merge(data_df, truth_data_df, on=\"id\")\n",
    "features = [\"id\", \"postMedia\", \"postText\", \"targetCaptions\", \"targetParagraphs\", \"targetTitle\", \"targetKeywords\",\n",
    "                \"targetDescription\", \"truthClass\"]\n",
    "vals = train[features]\n",
    "vals = vals.values.tolist()\n",
    "for i in range(len(vals)):\n",
    "    if vals[i][1] != []:\n",
    "        final_vals.append([vals[i][0], [vals[i][1][0]], vals[i][2], vals[i][3], vals[i][4], vals[i][5], vals[i][6], vals[i][7], vals[i][8]])\n",
    "\n",
    "vals_df = pd.DataFrame(final_vals, columns=[\"id\", \"postMedia\", \"postText\", \"targetCaptions\", \"targetParagraphs\", \"targetTitle\", \"targetKeywords\",\n",
    "                \"targetDescription\", \"truthClass\"])\n",
    "print(\"Final vals length\", len(final_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finalTestVals length 1011\n"
     ]
    }
   ],
   "source": [
    "finalTestvals = []\n",
    "test_data_df = pd.DataFrame.from_dict(test_data)\n",
    "test = pd.merge(test_data_df, truth_data_df, on=\"id\")\n",
    "test_vals = test[features].values.tolist()\n",
    "for i in range(len(test_vals)):\n",
    "    if test_vals[i][1] != []:\n",
    "        finalTestvals.append([test_vals[i][0], [test_vals[i][1][0]], test_vals[i][2], test_vals[i][3], test_vals[i][4], test_vals[i][5], test_vals[i][6], test_vals[i][7], test_vals[i][8]])\n",
    "\n",
    "test_vals_df = pd.DataFrame(finalTestvals, columns=[\"id\", \"postMedia\", \"postText\", \"targetCaptions\", \"targetParagraphs\", \"targetTitle\", \"targetKeywords\",\n",
    "                \"targetDescription\", \"truthClass\"])\n",
    "print(\"finalTestVals length\", len(finalTestvals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the CNN from ./vgg16_no_fc.npy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 4/13 [00:00<00:00, 37.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv4_3\n",
      "conv3_3\n",
      "conv1_1\n",
      "conv3_2\n",
      "conv4_2\n",
      "conv4_1\n",
      "conv2_1\n",
      "conv1_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 36.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv5_2\n",
      "conv5_3\n",
      "conv2_2\n",
      "conv3_1\n",
      "conv5_1\n",
      "26 tensors loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "image_features = imgModel(vals_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the CNN from ./vgg16_no_fc.npy...\n",
      "conv1_2\n",
      "conv4_2\n",
      "conv4_1\n",
      "conv4_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 11/13 [00:00<00:00, 40.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv3_1\n",
      "conv3_3\n",
      "conv1_1\n",
      "conv2_1\n",
      "conv3_2\n",
      "conv2_2\n",
      "conv5_1\n",
      "conv5_2\n",
      "conv5_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 36.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 tensors loaded.\n"
     ]
    }
   ],
   "source": [
    "image_features_test = imgModel(test_vals_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = get_labels(vals_df)\n",
    "tlabels = get_labels(test_vals_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9283 unique tokens.\n",
      "Found 252166 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "title_train = get_title_df(vals_df.values.tolist())\n",
    "content_train = get_content_df(vals_df.values.tolist())\n",
    "\n",
    "title_train_df, t_word_index = get_padded_sequences(title_train)\n",
    "content_train_df, c_word_index = get_padded_sequences(content_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1036 unique tokens.\n",
      "Found 55792 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "title_test = get_title_df(test_vals_df.values.tolist())\n",
    "content_test = get_content_df(test_vals_df.values.tolist())\n",
    "\n",
    "title_test_df = get_padded_sequences(title_test)\n",
    "content_test_df = get_padded_sequences(content_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (9295, 1000)\n",
      "Shape of label tensor: (9295, 2)\n"
     ]
    }
   ],
   "source": [
    "labels = to_categorical(np.asarray(labels))\n",
    "print('Shape of data tensor:', title_train_df.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "\n",
    "indices = np.arange(title_train_df.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = title_train_df[indices]\n",
    "content_data = content_train_df[indices]\n",
    "# image_data = image_features[indices]\n",
    "labels = labels[indices]\n",
    "nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_features_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-0fc1ee96990f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mx_title_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtitle_test_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mx_content_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontent_test_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mx_image_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_features_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image_features_test' is not defined"
     ]
    }
   ],
   "source": [
    "x_title_train = data[:-nb_validation_samples]\n",
    "x_content_train = content_data[:-nb_validation_samples]\n",
    "# x_image_train = image_features[:-nb_validation_samples]\n",
    "y_train = labels[:-nb_validation_samples]\n",
    "\n",
    "x_title_val = data[-nb_validation_samples:]\n",
    "x_content_val = content_data[-nb_validation_samples:]\n",
    "# x_image_val = image_features[-nb_validation_samples:]\n",
    "y_val = labels[-nb_validation_samples:]\n",
    "\n",
    "x_title_test = title_test_df\n",
    "x_content_test = content_test_df\n",
    "x_image_test = image_features_test\n",
    "y_test = tlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training and validation sets')\n",
    "print(y_train.sum(axis=0))\n",
    "print(y_val.sum(axis=0))\n",
    "\n",
    "embeddings_index = {}\n",
    "f=open('glove.6B.100d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Total %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_embedding_matrix = np.random.random((len(t_word_index) + 1, EMBEDDING_DIM)) ##Titles\n",
    "for word, i in t_word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        t_embedding_matrix[i] = embedding_vector\n",
    "\n",
    "c_embedding_matrix = np.random.random((len(c_word_index) + 1, EMBEDDING_DIM)) ##Content\n",
    "for word, i in c_word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        c_embedding_matrix[i] = embedding_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(len(t_word_index) + 1, EMBEDDING_DIM, weights=[t_embedding_matrix], input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=True)\n",
    "\n",
    "content_embedding_layer = Embedding(len(c_word_index) + 1, EMBEDDING_DIM, weights=[c_embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='float32')\n",
    "content_data_input = Input(shape=(MAX_SEQUENCE_LENGTH,),dtype='float32')\n",
    "image_data_input = Input(shape=(100352,), dtype='float32')\n",
    "\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "l_lstm = Bidirectional(LSTM(100))(embedded_sequences)\n",
    "\n",
    "content_embedded_sequences = content_embedding_layer(content_data_input)\n",
    "l_lstm_content = Bidirectional(LSTM(100))(content_embedded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-----------------------------\")\n",
    "print(l_lstm.shape)\n",
    "\n",
    "preds_title = Dense(2, activation='softmax')(l_lstm)\n",
    "\n",
    "preds_content = Dense(2,activation='softmax')(l_lstm_content)\n",
    "\n",
    "preds_image = Dense(2, activation='softmax')(image_data_input)\n",
    "\n",
    "preds_add = concatenate([preds_title, preds_content, preds_image], axis =-1)\n",
    "\n",
    "preds = Dense(2)(preds_add)\n",
    "\n",
    "model = Model([sequence_input, content_data_input, image_data_input], preds)\n",
    "# model1.add_update(ac.AttentionWithContext()) ###############\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"weights-text-{epoch:02d}-{val_acc:.2f}.hdf5\")\n",
    "callbacks_list = [checkpoint]\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model fitting - Bidirectional LSTM with titles and content\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1000, 100)    928400      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1000, 100)    25216700    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 200)          160800      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 200)          160800      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 100352)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            402         bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            402         bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            200706      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6)            0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            14          concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 26,668,224\n",
      "Trainable params: 26,668,224\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "print(\"model fitting - Bidirectional LSTM with titles and content\")\n",
    "model.summary()\n",
    "print('------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8262 samples, validate on 1033 samples\n",
      "Epoch 1/10\n",
      "8262/8262 [==============================] - 4886s 591ms/step - loss: 0.5253 - acc: 0.2115 - val_loss: 0.4807 - val_acc: 0.2120\n",
      "Epoch 2/10\n",
      "8262/8262 [==============================] - 4663s 564ms/step - loss: 0.4533 - acc: 0.1947 - val_loss: 0.4860 - val_acc: 0.1955\n",
      "Epoch 3/10\n",
      "8262/8262 [==============================] - 4733s 573ms/step - loss: 0.4288 - acc: 0.1871 - val_loss: 0.4680 - val_acc: 0.2033\n",
      "Epoch 4/10\n",
      "8262/8262 [==============================] - 4480s 542ms/step - loss: 0.3969 - acc: 0.1675 - val_loss: 0.7220 - val_acc: 0.1946\n",
      "Epoch 5/10\n",
      "8262/8262 [==============================] - 4590s 556ms/step - loss: 0.3697 - acc: 0.1469 - val_loss: 0.7902 - val_acc: 0.1965\n",
      "Epoch 6/10\n",
      "8262/8262 [==============================] - 3172s 384ms/step - loss: 0.3569 - acc: 0.1239 - val_loss: 1.0804 - val_acc: 0.1994\n",
      "Epoch 7/10\n",
      "8262/8262 [==============================] - 11399s 1s/step - loss: 0.3701 - acc: 0.1068 - val_loss: 1.0930 - val_acc: 0.2410\n",
      "Epoch 8/10\n",
      "8262/8262 [==============================] - 3321s 402ms/step - loss: 0.2790 - acc: 0.0862 - val_loss: 1.4481 - val_acc: 0.2207\n",
      "Epoch 9/10\n",
      "8262/8262 [==============================] - 13326s 2s/step - loss: 0.2424 - acc: 0.0600 - val_loss: 1.7039 - val_acc: 0.2575\n",
      "Epoch 10/10\n",
      "8262/8262 [==============================] - 9511s 1s/step - loss: 0.2382 - acc: 0.0405 - val_loss: 2.1481 - val_acc: 0.2827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f38b87b82e8>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " model.fit([x_title_train, x_content_train, np.asarray(x_image_train)], y_train, validation_data=([x_title_val, x_content_val, np.asarray(x_image_val)], y_val), epochs=10, batch_size=50, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('weights-text-02-0.20.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7e7191e2857e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_title_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_content_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_image_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "preds = model.predict([x_title_test, x_content_test, np.asarray(x_image_test)], batch_size=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_new = []\n",
    "for i in range(len(preds)):\n",
    "    preds_new.append(preds[i][0] + preds[i][1])\n",
    "print(\"Accuracy score on Test data \", accuracy_score(y_test, np.asarray(preds_new).round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1011\n"
     ]
    }
   ],
   "source": [
    "print(len(x_image_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
